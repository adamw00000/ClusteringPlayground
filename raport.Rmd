---
output:
  html_document: default
  pdf_document: default
---
# PDRPy - Praca domowa nr 2

## Wstęp

Zadanie polegało na zaimplementowaniu algorytmu spektralnego analizy skupień z użyciem Rcpp oraz porównaniu go z innymi algorytmami zapewnianymi przez R oraz dostępnymi na CRAN. Zbiór przetestowanych algorytmów obejmuje:

* **Algorytm spektralny** z parametrem M:
    * M = 2 - *spectral_M2*
    * M = 5 - *spectral_M5*
    * M = 8 - *spectral_M8*
    * M = 10 - *spectral_M10*
    * M = 12 - *spectral_M12*
    * M = 15 - *spectral_M15*
    * M = 20 - *spectral_M20*
    * M = 30 - *spectral_M30*
    * M = k, gdzie k jest oczekiwaną liczbą skupień - *spectral_Mk*
* **Algorytm k-średnich** z pakietu wbudowanego stats - *kmeans*
* **Algorytm hierarchiczny hclust** z pakietu wbudowanego stats:
    * różne sposoby tworzenie dendrogramu - *hclust_ward.D, hclust_ward.D2, hclust_single, hclust_complete, hclust_average,hclust_mcquitty, hclust_median, hclust_centroid* oraz *hclust_centroid2*. Druga część nazwy odpowiada zastosowanemu wariantowi algorytmu. Dwa sposoby wywołania algorytmu *hclust centroid* wynikają z faktu, że w dokumentacji sugerowaną metodą obliczania odległości dla algorytmu jest nie zwyczajna odległość Euklidesowa realizowana przez funkcję *hclust_centroid*, a odległość Euklidesowa podniesiona do kwadratu (*hclust_centroid2*)
* **Algorytm hclust2** z pakietu CRAN genie z parametrem gini (0 - 1):
    * gini = 0.2 - *genie_0.2*
    * gini = 0.3 (wartość domyślna) - *genie_0.3*
    * gini = 0.5 - *genie_0.5*
    * gini = 0.8 - *genie_0.8*
* **Algorytm Fuzzy C-Means** z pakietu CRAN advclust - z parametrem fuzzyfier (> 1):
    * fuzzyfier = 1.5 (wartość domyślna) - *fuzzy_default*
    * fuzzyfier = 2 - *fuzzy_2*
    * fuzzyfier = 5 - *fuzzy_5*
    * fuzzyfier = 10 - *fuzzy_10*
* Podjąłem również próbę zastosowania **algorytmu DBSCAN**, jednak ze względu na nadzwyczajną wrażliwość na parametry nie nadawał się on do wykorzystania w tak ogólnych testach.
    
Skrótowe nazwy pojawiające się w powyższym będą używane do identyfikacji algorytmów również dalej.

## Algorytm spektralny

Implementacja algorytmu spektralnego została zrealizowana jako pakiet R. Aby móc go używać, należy zbudować oraz zainstalować projekt zawarty w folderze **MySpectralClustering**. W implementacji funkcji `Mnn()` z uwagi na jak największą wydajność algorytmu została wykorzystana zewnętrzna implementacja kd-drzewa dostępna pod licencją MIT na [githubie](https://github.com/gishi523/kd-tree). Z tego samego względu w Rcpp zostały zaimplementowane fragmenty pozostałych funkcji. Szczegółowe testy tej metody zostały opisane w dokumencie **testy.pdf**.

## Pozostałe elementy rozwiązania

Foldery **benchmark** oraz **my_benchmark** zawierają odpowiednio dołączone do zadania zbiory benchmarkowe oraz zbiory wygenerowane jako część rozwiązania zadania (zostały one wygenerowane za pomocą plików **graph.R, labirynth.R oraz windows.R**). Uruchamianie zaimplementowanych algorytmów jest realizowane w pliku **benchmark_executor.R**. Uzyskane wyniki znajdują się odpowiednio w folderach **output** oraz **my_benchmark_output**, podzielone względem algorytmów. Wizualizacja wszystkich wyników jest załączona w pliku **full_results.html**. W dalszej części tego dokumentu skupię się na zebraniu w całość i opracowaniu wyników otrzymanych dla załączonych danych benchmarkowych.

## Opracowanie wyników

Porównanie otrzymanych wyników zostanie wykonane za pomocą wyznaczonych dla każdego rozwiązania skorygowanego indeksu Randa **(AR)** oraz indeksu Fowlkesa-Mallowsa **(FM)**.

```{R, echo = FALSE, message=FALSE}
load_results <- function()
{
  dataBasePath <- file.path(getwd(), "output")
  dirs <- list.dirs(dataBasePath)
  
  result_collection <- list()
  standardized_result_collection <- list()
  
  for (i in 2:length(dirs))
  {
    dirFiles <- list.files(dirs[i], pattern = ".*\\.csv")
    absoluteFiles <- file.path(dirs[i], dirFiles)
    
    dirData <- list()
    for (j in 1:length(absoluteFiles))
    {
      fileData <- read.csv(absoluteFiles[j], sep = "")
    
      name <- basename(absoluteFiles[j])
      name <- tools::file_path_sans_ext(name)
      dirData[[name]] <- fileData[[1]]
    }
    
    if (stringi::stri_detect_fixed(dirs[i], "_standardized"))
    {
      standardized_result_collection <- c(standardized_result_collection, list(dirData))
    }
    else
    {
      result_collection <- c(result_collection, list(dirData))
    }
  }
  results <- list(normal = result_collection, standardized = standardized_result_collection)
}

load_results_data <- function(results)
{
  load_results_data_helper <- function(resultList)
  {
    for (i in 1:length(resultList))
    {
      baseDir <- file.path(getwd(), "benchmark")
      
      dataFile <- resultList[[i]]$data_file[[1]]
      data <- read.csv(file.path(baseDir, dataFile), sep = '', header = FALSE)
      resultList[[i]][["data"]] <- data
    }
    resultList
  }
  results$normal <- load_results_data_helper(results$normal)
  results$standardized <- load_results_data_helper(results$standardized)
  
  results
}

calculate_indices_df <- function(results)
{
  indices <- data.frame()
  
  calculate_indices_helper <- function(resultList, indices, standardized)
  {
    for (i in 1:length(resultList))
    {
      resultSet <- resultList[[i]]
      for (j in 1:length(resultSet))
      {
        name <- names(resultSet)[j]
        if (!stringi::stri_detect_regex(name, "(data_file)|(data)|(expert)"))
        {
          randIndex <- mclust::adjustedRandIndex(resultSet$expert, resultSet[[name]])
          fmIndex <- as.numeric(dendextend::FM_index(resultSet$expert, resultSet[[name]]))
          
          indices <- rbind(indices, data.frame(Algorithm = name, Standardized = standardized,
                                               FileId = i, Index = "rand",
                                               Value = randIndex))
          indices <- rbind(indices, data.frame(Algorithm = name, Standardized = standardized,
                                               FileId = i, Index = "fm",
                                               Value = fmIndex))
        }
      }
    }
    indices
  }
  
  indices <- calculate_indices_helper(results$normal, indices, FALSE)
  indices <- calculate_indices_helper(results$standardized, indices, TRUE)
  indices
}

results <- load_results()
results <- load_results_data(results)

indices <- calculate_indices_df(results)
```

### Zagregowane indeksy Randa i FM

Dla dostarczonych danych benchmarkowych obliczone zostały średnie wartości indeksów AR i FM. Porównane zostały one również z wartościami tych indeksów dla danych ustandaryzowanych, z uwzględnieniem zmiany spowodowanej przez standardyzację. Zestawienie otrzymanych wyników znajduje się w poniższych tabelach. Zostały one posortowane poczynając od największych wartości dla indeksu AR i zaokrąglone do trzech cyfr po przecinku.


```{r, echo=FALSE, message=FALSE, results='asis'}
library(dplyr)
library(kableExtra)

aggregateIndices_df <- function(indices, operation = mean, differences = TRUE)
{
  randNormal <- indices %>%
      filter(Index == "rand" & Standardized == TRUE) %>%
      group_by(Algorithm) %>%
      summarize("RA" = round(operation(Value), 3))
  randSt <- indices %>%
      filter(Index == "rand" & Standardized == FALSE) %>%
      group_by(Algorithm) %>%
      summarize("RAtmp" = round(operation(Value), 3))
  fmNormal <- indices %>%
      filter(Index == "fm" & Standardized == TRUE) %>%
      group_by(Algorithm) %>%
      summarize("FM" = round(operation(Value), 3))
  fmSt <- indices %>%
      filter(Index == "fm" & Standardized == FALSE) %>%
      group_by(Algorithm) %>%
      summarize("FMtmp" = round(operation(Value), 3))

  gen_color <- function(diffValue, gap) ifelse(diffValue >= gap, "blue", 
                                          ifelse(diffValue >= gap/2, "cornflowerblue", 
                                            ifelse(diffValue <= -gap, "red", 
                                              ifelse(diffValue <= -gap/2, "orange", 
                                              "black"))))
  
  resultView <- randNormal %>%
    inner_join(randSt) %>%
    inner_join(fmNormal) %>%
    inner_join(fmSt) %>%
    mutate("RA - difference" = kableExtra::cell_spec(round(RAtmp - RA, 3), "html", align = "r",
                                                color = gen_color(round(RAtmp- RA, 3), 0.1))) %>%
    rename("RA - st. data" = RAtmp) %>%
    mutate("FM - difference" = kableExtra::cell_spec(round(FMtmp - FM, 3), "html", align = "r",
                                                color = gen_color(round(FMtmp - FM, 3), 0.05))) %>%
    rename("FM - st. data" = FMtmp)
  
  resultView <- if(differences) 
    resultView %>%
      select("Algorithm",
             "RA", "RA - st. data", "RA - difference",
             "FM", "FM - st. data", "FM - difference")
  else
    resultView %>%
      select("Algorithm",
             "RA", "RA - st. data", 
             "FM", "FM - st. data")

  resultView %>%
    arrange(-RA)
}

knitr::kable(aggregateIndices_df(indices, mean),"markdown",
             caption = "Średnie wartości indeksów",
             escape = FALSE,
             align = c("lcccccc"))
```

Na podstawie otrzymanych wyników można poczynić kilka obserwacji.

* Wartości obu indeksów, pomimo, że odbiegają od siebie, zachowują się podobnie. Pomimo, że wartości są posortowane względem indeksu AR, możemy zaobserwować (z nieznacznymi odstępstwami) wyraźny malejący trend również dla kolumn odpowiadających indeksowi FM. W dalszej części dokumentu skupimy się na "rankingu" tworzonym przez indeks AR.
* Wpływ standardyzacji zmiennych na zdecydowaną większość algorytmów analizy skupień jest znikomy. Wartości różnicy $d$ dla danych ustandaryzowanych zostały oznaczone kolorami: 
    * $d \leq -0.1$ - czerwony, 
    * $-0.1 \le d \leq -0.05$ - pomarańczowy, 
    * $-0.05 \le d \le 0.05$ - czarny, 
    * $0.05 \leq d \le 0.1$  - jasnoniebieski, 
    * $0.1 \leq d$ - ciemnoniebieski  
dla indeksu AR, natomiast połowa tych wartości dla indeksu FM. 

    Różnice znaczące (oznaczone kolorami innymi niż czarny) występują bardzo rzadko. Łatwo też zauważyć, że zdarzają się one zwykle w przypadku algorytmów "gorszych", o niższych wartościach indeksóW - najczęściej źle skalibrowanych (złe parametry) lub po prostu działających jedynie w szczególnych przypadkach. Niemniej jednak, sytuacje, gdy standardyzacja przynosi zły efekt praktycznie nie występują - przeważająca większość różnic ma znak dodatni.
* Dobrze (uniwersalnie) skalibrowany algorytm genie osiąga o wiele lepsze wyniki niż którykolwiek z innych testowanych algorytmów. Proponowany przez twórców parametr gini równy 0.3 rzeczywiście osiąga uniwersalnie najlepsze wyniki. Delikatne odchylenia od tej wartości nadal osiągają uniwersalnie zadowalające wyniki. Jednak nawet z paremetrem gini tak dużym jak 0.8 algorytm ten jest uniwersalnie lepszy od większej części innych algorytmów, natomiast ma swoją niszę - są przypadki, dla których generuje on rozwiązanie najlepsze.
* Tradycyjne algorytmy hierarchiczne osiągają bardzo rozbieżne wyniki w zależności od zastosowanej metody. Najlepsze z nich okazują się te oparte na algorytmie Warda, natomiast zdecydowanie najgorszy - algorytm medianowy. Znajdujący się ponad nim algorytm centroidowy bardzo dużo zyskuje na przekazaniu mu kwadratów odległości - algorytm *hclust_centroid2* osiąga znacznie lepsze wyniki niż *hclust_centroid*.
* Algorytm spektralny osiąga przeciętne wyniki. Wartość parametru M (liczby sąsiadów) ma dla niego duże znaczenie - wartości rzędu kilkunastu okazały się działać najlepiej, okazując się lepsze od tradycyjnego algorytmu k-średnich. Dobrym pomysłem okazało się również uzależnienie parametru M od liczby poszukiwanych skupień. Bardzo małe oraz bardzo duże wartości M powodują spadek ogólnej jakości algorytmu, ale mają swoją niszę. Wyjątkiem jest M równe (oraz mniejsze niż) 2 - wyniki w ten sposób otrzymane okazują się być bardzo złej jakości. Dużą wadą algorytmu jest też długi czas wykonania w przypadku dużych zbiorów danych, związany głównie z czasochłonnym procesem znajdowania wektorów własnych.
* Algorytm Fuzzy C-Means dla wartości fuzzyfiera zbliżonych do domyślnej (1.5) osiąga bardzo dobre wyniki, chociaż nadal bardzo daleko mu do algorytmu gini. Zbytni wzrost fuzzyfiera powoduje jednak znaczny spadek jakości algorytmu. Podobnie jak algorytm spektralny, czas wykonania dla dużych zbiorów danych może być długi (zależnie od prędkości zbieżności).

Obliczyłem również wartości odchylenia standardowego dla wszystkich indeksów.

```{r, echo=FALSE, message=FALSE, results='asis'}
knitr::kable(aggregateIndices_df(indices, sd, differences = FALSE), "markdown",
             caption = "Odchylenie standardowe wartości indeksów",
             escape = FALSE,
             align = c("lcccc"))
```

Również stąd możemy wyciągnąć użyteczne informacje:

* Wartości odchylenia standardowego dla większości algorytmów są stosunkowo duże. Pokazuje to, że są one wrażliwe na wybranie dobrego przypadku użycia dla danego algorytmu.
* Górna część tabeli obejmuje algorytmy "wyspecjalizowane". Algorytm *hclust_single*, pomimo osiągania ogólnie złych wyników, okazuje się jednak mieć potencjał w bardzo wielu przypadkach - podobnie jak większość algorytmów hierarchicznych. Zgodnie ze wcześniejszym stwierdzeniem, do grupy "specjalistów" należy również algorytm *genie_0.8*.
* Dolna część tabeli wskazuje na osiąganie w miarę zbliżonych wyników - jeśli szukamy algorytmu uniwersalnego, chcemy wybrać jeden z nich. Należy jednak uważać - o ile algorytm *spectral_k* i algorytmy z rodziny *genie* są świetnymi algorytmami uniwersalnymi, *spectral_M2* jest uniwersalnie beznadziejny.

Następnym wykonanym przeze mnie krokiem było wykonanie wykresów skrzynkowych dla obu algorytmów.

```{r, echo=FALSE}
boxplotIndices <- function(indices)
{
  randNormal <- indices %>%
      filter(Index == "rand" & Standardized == TRUE)
  
  draw_boxplot <- function(df, label)
  {
    bpm <- with(df, reorder(Algorithm, -Value, FUN = median))
    
    par(mar=c(7,5,1,1))
    boxplot(Value ~ bpm, data = df, las = 2, xlab = "", ylab = label)
  }
  
  draw_boxplot(randNormal, "Rand index value")
  
  randSt <- indices %>%
      filter(Index == "rand" & Standardized == FALSE)
  fmNormal <- indices %>%
      filter(Index == "fm" & Standardized == TRUE)
  
  draw_boxplot(fmNormal, "FM index value")
  
  fmSt <- indices %>%
      filter(Index == "fm" & Standardized == FALSE)
  
}
boxplotIndices(indices)
```

## Wyniki

### Dane surowe

```{r, echo=FALSE, message=FALSE}
plot_results <- function(resultsCollection) 
{
  for (i in 1:length(resultsCollection))
  {
    resultSet <- resultsCollection[[i]]
    
    data <- resultSet$data
    
    create_plot <- function(data, dataFile, name, expertLabels, labels)
    {
      randIndex <- round(mclust::adjustedRandIndex(expertLabels, labels), 2)
      fmIndex <- as.numeric(round(dendextend::FM_index(expertLabels, labels), 2))
        
      library(ggplot2)
      #if (length(data) == 2)
      #{
        plot(data[[1]], data[[2]], col=labels,  xlab = "", ylab = "",
                           main = paste(dataFile, "\n", 
                                  name, 
                                  "\nRand index:", randIndex, ", FM index:", fmIndex))
      #}
      #else if (length(data) == 3)
      #{
        
      #}
    }
    
    par(mfrow=c(1, 1))
    create_plot(data, resultSet$data_file, "expert", resultSet$expert, resultSet$expert)
    
    par(mfrow=c(2, 2))
    
    for (j in 1:length(resultSet))
    {
      name <- names(resultSet)[j]
      if (!stringi::stri_detect_regex(name, "(data_file)|(data)|(expert)"))
      {
        create_plot(data, resultSet$data_file, name, resultSet$expert, resultSet[[j]])
      }
    }
  }
}

#plot_results(results$normal)
```

### Dane ustandaryzowane
```{r, echo=FALSE, message=FALSE}
#plot_results(results$standardized)
```